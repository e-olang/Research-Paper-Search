{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olang/opt/miniconda3/envs/nlp2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "titles_path = 'titles.pkl'\n",
    "embeddings_path = 'embeddings.pkl'\n",
    "#index_path = 'data/index.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy array from pickle file\n",
    "with open('titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "titles = np.array(titles)\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk as a pickle file\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "384\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "sample = 'What is the best way to learn Python?'\n",
    "#print(model.encode([sample]))\n",
    "#print(loaded_model.encode([sample]))\n",
    "print('---------------------' * 3)\n",
    "print(len(model.encode([sample])[0]))\n",
    "print(len(loaded_model.encode([sample])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "nlist = 50\n",
    "m = 8\n",
    "bits = 8\n",
    "dimensions = embeddings.shape[1]\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(dimensions)\n",
    "index = faiss.IndexIVFPQ(quantizer, dimensions, nlist, m, bits)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24469\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "index.train(embeddings)\n",
    "index.add(embeddings)\n",
    "print(index.ntotal)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index to disk as a pickle file\n",
    "index_filename = 'index.sav'\n",
    "pickle.dump(index, open(index_filename, 'wb'))\n",
    "\n",
    "# load the index from disk\n",
    "loaded_index = pickle.load(open(index_filename , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.174143  1.2508657 1.2596219 1.2784854 1.2793882]]\n",
      "CPU times: user 109 ms, sys: 29.1 ms, total: 138 ms\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 5\n",
    "D, I = index.search(model.encode([str(input(\"Enter Query: \"))]), k)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15695  7873 15016 18628 10918]]\n"
     ]
    }
   ],
   "source": [
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15695: FNTF: First No-reference Then Full-reference image quality assessment using Dark Channel.',\n",
       " '7873: Rectification of figures and photos in document images using bounding box interface.',\n",
       " '15016: Design and Implementation of QoS-driven Dynamic Slot Assignment and Piconet Partitioning Algorithms over Bluetooth WPANs.',\n",
       " '18628: PiCode: 2D barcode with embedded picture and ViCode: 3D barcode with embedded video.',\n",
       " '10918: MANTRA: Minimum Maximum Latent Structural SVM for Image Classification and Ranking.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {titles[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Learning Where You Are Going and from Whence You Came: h- and g-Cost Learning in Real-Time Heuristic Search.',\n",
       " 'Learning by Reading: A Prototype System, Performance Baseline and Lessons Learned.',\n",
       " 'Integrating learning objects into an open learning environment: evaluation of learning processes in an informatics learning lab.',\n",
       " 'Typing Tutor: Individualized Tutoring in Text Entry for Older Adults Based on Input Stumble Detection.',\n",
       " 'Analogy Tutor: A Tutoring System for Promoting Conceptual Learning via Comparison.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample function to get the top k similar documents, with default k=5\n",
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    D, I = index.search(model.encode([query]), k)\n",
    "    return [titles[i] for i in I[0]]\n",
    "\n",
    "get_similar_documents('What is the best way to learn Python?', loaded_index, loaded_model, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    D, I = index.search(model.encode([query]), k)\n",
    "    for i in I:\n",
    "        print(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bits of History, Challenges for the Future and Autonomic Computing Technology.'\n",
      " 'Empirically Studying Software Practitioners - Bridging the Gap between Theory and Practice.'\n",
      " 'The evolution of C programming practices: a study of the Unix operating system 1973-2015.'\n",
      " 'A living laboratory for the design and evaluation of ubiquitous computing technologies.'\n",
      " '15 Years of Application of Statistical Physics Methods to the Study of Software Systems.']\n"
     ]
    }
   ],
   "source": [
    "query = str(input(\"Enter Query: \"))\n",
    "get_similar_documents(query, loaded_index, loaded_model, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brief Announcement: Fast and Simple Node Coloring in the SINR Model.'\n",
      " 'The Dirac-Motzkin Problem on Ordinary Lines and the Orchard Problem (Invited Talk).'\n",
      " 'Compressed suffix arrays and suffix trees with applications to text indexing and string matching (extended abstract).'\n",
      " 'Linear-Time Algorithms for Two Subtree-Comparison Problems on Phylogenetic Trees with Different Species.'\n",
      " 'Minimal Tail-Biting Trellises for Certain Cyclic Block Codes Are Easy to Construct.']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# load numpy arrays from pickle file\n",
    "\"\"\" with open('titles_np.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f) \"\"\"\n",
    "\n",
    "'''with open('embeddings_np.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)'''\n",
    "\n",
    "# load the model\n",
    "#model = pickle.load(open('model.sav' , 'rb'))\n",
    "\n",
    "# load the index from disk\n",
    "#index = pickle.load(open('index.sav' , 'rb'))\n",
    "\n",
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq\n",
    "\n",
    "\n",
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "    for i in I:\n",
    "        print(titles[i])\n",
    "\n",
    "query = str(input(\"Enter Query: \"))\n",
    "get_similar_documents(query, index, model, titles)\n",
    "\n",
    "#get_similar_documents('What is the best way to learn Python?', index, model, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Galaxies in the Shadows of Quasars with Gaussian Processes.\n"
     ]
    }
   ],
   "source": [
    "with open('titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "# convert to numpy array\n",
    "titles = np.array(titles)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# ----------------- model  -----------------\n",
    "#model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "# load model\n",
    "model = pickle.load(open('model.sav' , 'rb'))\n",
    "\n",
    "# ----------------- faiss_index  -----------------\n",
    "nlist = 50\n",
    "m = 8\n",
    "bits = 8\n",
    "dimensions = embeddings.shape[1]\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(dimensions)\n",
    "index = faiss.IndexIVFPQ(quantizer, dimensions, nlist, m, bits)\n",
    "index.train(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "# ----------------- search  -----------------\n",
    "\n",
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq\n",
    "\n",
    "def get_similar_documents(query, index=index, model=model, titles=titles, k=5):\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "   \n",
    "    print(titles[I[0][0]])\n",
    "\n",
    "\n",
    "query = 'Quavo'\n",
    "get_similar_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(query):\n",
    "    k = 10\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "    # return list of similar documents\n",
    "    return [titles[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test funct.\n",
    "def name(text):\n",
    "    return 'Hello ' + text, 'Hello ' + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello John', 'Hello John')\n",
      "['Floats and Ropes: A Case Study for Formal Numerical Program Verification.', 'Digital Libraries: Extending and Applying Library and Information Science and Technology.', 'The fractal dimension metric and its use to assess object-oriented software quality.', 'UX research: what theoretical roots do we build on - if any?', \"Don't look now, but we've created a bureaucracy: the nature and roles of policies and rules in wikipedia.\", 'Academic Software Engineering: What Is and What Could Be? Results of the First Annual Survey for International SE Programs.', \"Design requirements for more flexible structured editors from a study of programmers' text editing.\", 'Ten steps of integrating user feedback into the product definition process: a closed loop approach.', 'Using knowledge elicitation to improve Web effort estimation: Lessons from six industrial case studies.', 'Java Program Analysis Projects in Osaka University: Aspect-Based Slicing System ADAS and Ranked-Component Search System SPARS-J.']\n"
     ]
    }
   ],
   "source": [
    "print(name('John'))\n",
    "print(get_similar_documents('maths'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=get_similar_documents,\n",
    "    inputs = gr.Textbox(lines=1, placeholder=\"Enter Query...\", label=\"Query\"),\n",
    "\n",
    "    # variable number of outputs based on the number of results argument \n",
    "    outputs = [ gr.outputs.Textbox(label=\"First similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Second similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Third similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Fourth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Fifth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Sixth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Seventh similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Eighth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Ninth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Tenth similar document\")],\n",
    "   \n",
    "    title=\"Search Engine\",\n",
    "    description=\"Search Engine using Sentence Transformers and Faiss Indexing\",\n",
    "    allow_flagging=False,\n",
    "    allow_screenshot=False,\n",
    "    allow_output_caching=False,\n",
    "\n",
    "    )\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
