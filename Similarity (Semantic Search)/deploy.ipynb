{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Files/titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('Files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "with open('Files/authors.pkl', 'rb') as f:\n",
    "    authors = pickle.load(f)\n",
    "\n",
    "with open('Files/years.pkl', 'rb') as f:\n",
    "    years = pickle.load(f)\n",
    "\n",
    "with open('Files/summary.pkl', 'rb') as f:\n",
    "    summary = pickle.load(f)\n",
    "\n",
    "index = pickle.load(open('Files/index.sav' , 'rb'))\n",
    "\n",
    "#model = pickle.load(open('Files/model.sav' , 'rb'))\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple query to return the first 5 similar documents (Titles, Authors, Years, Summary)\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = []\n",
    "    for i in range(k):\n",
    "        results.append(\n",
    "            { \n",
    "                'Title': titles[I[0][i]],\n",
    "                'Author': authors[I[0][i]],\n",
    "                'Year': years[I[0][i]],\n",
    "                'Summary': summary[I[0][i]]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" for result in results:\\n    print(result['Title'])\\n    print(result['Author'])\\n    print(result['Year'])\\n    print(result['Summary'])\\n    print('') \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing ðŸ˜€\n",
    "\n",
    "query = 'What is the best way to learn Python?'\n",
    "\n",
    "results = retrieve(query)\n",
    "\n",
    "\"\"\" for result in results:\n",
    "    print(result['Title'])\n",
    "    print(result['Author'])\n",
    "    print(result['Year'])\n",
    "    print(result['Summary'])\n",
    "    print('') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data):\n",
    "    base_path = 'Sample_jsons/'\n",
    "    excportpath = base_path + 'excport.json'\n",
    "    with open(excportpath, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    \n",
    "    print('JSON file created successfully')\n",
    "    return excportpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sample_jsons/excport.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing ðŸ˜€\n",
    "write_json(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list of dictionaries to json file\n",
    "with open('results3.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Gardio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=retrieve,\n",
    "    inputs = gr.inputs.Textbox(lines=1, placeholder=\"Enter Query...\", label=\"Query text\"),\n",
    "    # a json output with 4 keys: titles, authors, years, summary\n",
    "    outputs = gr.outputs.JSON(label=\"Similar Documents\"),\n",
    "    title=\"Semantic Search\",\n",
    "    description=\"Search for similar documents using semantic search.\",\n",
    "    allow_flagging=False,\n",
    "    examples=[\n",
    "        [\"Mathematical models of the spread of infectious diseases in humans and animals\"],\n",
    "        [\"A new method for solving the nonlinear eigenvalue problem\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f800075b4f0>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## JSON Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Result 1\": [\n",
      "        \"Integrative Imaging Informatics for Cancer Research: Workflow Automation\\n  for Neuro-oncology (I3CR-WANO)\",\n",
      "        \"Daniel S. Marcus\",\n",
      "        2022,\n",
      "        \"Efforts to utilize growing volumes of clinical imaging data to generate tumor\\nevaluations continue to require significant manual data wrangling owing to the\\ndata heterogeneity. Here, we propose an artificial intelligence-based solution\\nfor the aggregation and processing of multisequence neuro-oncology MRI data to\\nextract quantitative tumor measurements. Our end-to-end framework i) classifies\\nMRI sequences using an ensemble classifier, ii) preprocesses the data in a\\nreproducible manner, iii) delineates tumor tissue subtypes using convolutional\\nneural networks, and iv) extracts diverse radiomic features. Moreover, it is\\nrobust to missing sequences and adopts an expert-in-the-loop approach, where\\nthe segmentation results may be manually refined by radiologists. Following the\\nimplementation of the framework in Docker containers, it was applied to two\\nretrospective glioma datasets collected from the Washington University School\\nof Medicine (WUSM; n = 384) and the M.D. Anderson Cancer Center (MDA; n = 30)\\ncomprising preoperative MRI scans from patients with pathologically confirmed\\ngliomas. The scan-type classifier yielded an accuracy of over 99%, correctly\\nidentifying sequences from 380/384 and 30/30 sessions from the WUSM and MDA\\ndatasets, respectively. Segmentation performance was quantified using the Dice\\nSimilarity Coefficient between the predicted and expert-refined tumor masks.\\nMean Dice scores were 0.882 ($\\\\pm$0.244) and 0.977 ($\\\\pm$0.04) for whole tumor\\nsegmentation for WUSM and MDA, respectively. This streamlined framework\\nautomatically curated, processed, and segmented raw MRI data of patients with\\nvarying grades of gliomas, enabling the curation of large-scale neuro-oncology\\ndatasets and demonstrating a high potential for integration as an assistive\\ntool in clinical practice.\"\n",
      "    ],\n",
      "    \"Result 2\": [\n",
      "        \"An overview of the proposed INdian Spectroscopic and Imaging Space\\n  Telescope (INSIST)\",\n",
      "        \"Annapurni Subramaniam\",\n",
      "        2022,\n",
      "        \"India reached a major milestone in the area of space astronomy with the\\nsuccessful launch and post-launch operations of its first space observatory,\\nAstroSat. The success of this space observatory and the lessons learned must be\\nutilized effectively to enlarge the footprint of Indian space astronomy in the\\ninternational scene. In response to a call for proposals by the Indian Space\\nResearch Organisation, a detailed proposal for a next generation UV-optical\\nmission, the INdian Spectroscopic and Imaging Space Telescope (INSIST) was\\nsubmitted. Combining a large focal area with a simple and efficient optical\\ndesign, INSIST is expected to produce HST-quality imaging and moderate\\nresolution spectra of astronomical sources. The main science drivers for this\\nmission span a wide range of topics, starting from evolution of galaxies in\\ngroups and clusters, chemo-dynamics and demographics of the nearby universe,\\nstellar systems with accretions, to stars with planetary systems, to cosmology\\nnear and far. The proposal was awarded seed funding and has completed two years\\nof pre-project phase. An overview of this proposed mission is presented here\\nalong with the current status.\"\n",
      "    ],\n",
      "    \"Result 3\": [\n",
      "        \"Using Machine Learning to generate an open-access cropland map from\\n  satellite images time series in the Indian Himalayan Region\",\n",
      "        \"Thijs Defraeye\",\n",
      "        2022,\n",
      "        \"Crop maps are crucial for agricultural monitoring and food management and can\\nadditionally support domain-specific applications, such as setting cold supply\\nchain infrastructure in developing countries. Machine learning (ML) models,\\ncombined with freely-available satellite imagery, can be used to produce\\ncost-effective and high spatial-resolution crop maps. However, accessing ground\\ntruth data for supervised learning is especially challenging in developing\\ncountries due to factors such as smallholding and fragmented geography, which\\noften results in a lack of crop type maps or even reliable cropland maps. Our\\narea of interest for this study lies in Himachal Pradesh, India, where we aim\\nat producing an open-access binary cropland map at 10-meter resolution for the\\nKullu, Shimla, and Mandi districts. To this end, we developed an ML pipeline\\nthat relies on Sentinel-2 satellite images time series. We investigated two\\npixel-based supervised classifiers, support vector machines (SVM) and random\\nforest (RF), which are used to classify per-pixel time series for binary\\ncropland mapping. The ground truth data used for training, validation and\\ntesting was manually annotated from a combination of field survey reference\\npoints and visual interpretation of very high resolution (VHR) imagery. We\\ntrained and validated the models via spatial cross-validation to account for\\nlocal spatial autocorrelation and selected the RF model due to overall\\nrobustness and lower computational cost. We tested the generalization\\ncapability of the chosen model at the pixel level by computing the accuracy,\\nrecall, precision, and F1-score on hold-out test sets of each district,\\nachieving an average accuracy for the RF (our best model) of 87%. We used this\\nmodel to generate a cropland map for three districts of Himachal Pradesh,\\nspanning 14,600 km2, which improves the resolution and quality of existing\\npublic maps.\"\n",
      "    ],\n",
      "    \"Result 4\": [\n",
      "        \"A crowdsourced dataset of aerial images with annotated solar\\n  photovoltaic arrays and installation metadata\",\n",
      "        \"Laurent Dubus\",\n",
      "        2022,\n",
      "        \"Photovoltaic (PV) energy generation plays a crucial role in the energy\\ntransition. Small-scale PV installations are deployed at an unprecedented pace,\\nand their integration into the grid can be challenging since public authorities\\noften lack quality data about them. Overhead imagery is increasingly used to\\nimprove the knowledge of residential PV installations with machine learning\\nmodels capable of automatically mapping these installations. However, these\\nmodels cannot be easily transferred from one region or data source to another\\ndue to differences in image acquisition. To address this issue known as domain\\nshift and foster the development of PV array mapping pipelines, we propose a\\ndataset containing aerial images, annotations, and segmentation masks. We\\nprovide installation metadata for more than 28,000 installations. We provide\\nground truth segmentation masks for 13,000 installations, including 7,000 with\\nannotations for two different image providers. Finally, we provide installation\\nmetadata that matches the annotation for more than 8,000 installations. Dataset\\napplications include end-to-end PV registry construction, robust PV\\ninstallations mapping, and analysis of crowdsourced datasets.\"\n",
      "    ],\n",
      "    \"Result 5\": [\n",
      "        \"An associative memory model with very high memory rate: Image storage by\\n  sequential addition learning\",\n",
      "        \"Hiroshi Inazawa\",\n",
      "        2022,\n",
      "        \"In this paper, we present a neural network system related to about memory and\\nrecall that consists of one neuron group (the \\\"cue ball\\\") and a one-layer\\nneural net (the \\\"recall net\\\"). This system realizes the bidirectional\\nmemorization learning between one cue neuron in the cue ball and the neurons in\\nthe recall net. It can memorize many patterns and recall these patterns or\\nthose that are similar at any time. Furthermore, the patterns are recalled at\\nmost the same time. This model's recall situation seems to resemble human\\nrecall of a variety of similar things almost simultaneously when one thing is\\nrecalled. It is also possible for additional learning to occur in the system\\nwithout affecting the patterns memorized in advance. Moreover, the memory rate\\n(the number of memorized patterns / the total number of neurons) is close to\\n100%; this system's rate is 0.987. Finally, pattern data constraints become an\\nimportant aspect of this system.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# convert dict to json for HTML output\n",
    "import json\n",
    "\n",
    "x = json.dumps(results, indent = 4) \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json to file\n",
    "with open('HTML/results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Reserves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = {'titles': [], 'authors': [], 'years': [], 'summary': []}\n",
    "    for i in range(k):\n",
    "        results['titles'].append(titles[I[0][i]])\n",
    "        results['authors'].append(authors[I[0][i]])\n",
    "        results['years'].append(years[I[0][i]])\n",
    "        results['summary'].append(summary[I[0][i]])\n",
    "    \n",
    "    return results\n",
    "    #return [titles[i] for i in I[0]], [authors[i] for i in I[0]], [years[i] for i in I[0]], [summary[i] for i in I[0]]\n",
    "\n",
    "\n",
    "for i in range(len(results['titles'])):\n",
    "    print(results['titles'][i])\n",
    "    print(results['authors'][i])\n",
    "    print(results['years'][i])\n",
    "    print(results['summary'][i])\n",
    "    print('----------------------------------------' * 2)\n",
    "\n",
    "\n",
    "# write each item in the list to a json file on new line\n",
    "with open('results2.json', 'w') as f:\n",
    "    for item in results:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n' % item)\n",
    "\n",
    "\n",
    "# simple query to return the first 5 similar documents (Titles, Authors, Years, Summary)\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = {'Result 1': [], 'Result 2': [], 'Result 3': [], 'Result 4': [], 'Result 5': []}\n",
    "    for i in range(k):\n",
    "        results['Result '+str(i+1)].append(titles[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(authors[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(years[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(summary[I[0][i]])\n",
    "    return results\n",
    "\n",
    "\n",
    "## Draft for json output\n",
    "k = 5 # number of similar documents to return\n",
    "xq = model.encode(['Africa Technology'])\n",
    "D, I = index.search(xq, k)\n",
    "\n",
    "# store all dictionaries in a list\n",
    "results = []\n",
    "\n",
    "for i in range(k):\n",
    "    results.append({\n",
    "        'Title': titles[I[0][i]],\n",
    "        'Author': authors[I[0][i]],\n",
    "        'Year': years[I[0][i]],\n",
    "        'Summary': summary[I[0][i]]\n",
    "    })\n",
    "\n",
    "# write list of dictionaries to json file\n",
    "with open('results3.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
