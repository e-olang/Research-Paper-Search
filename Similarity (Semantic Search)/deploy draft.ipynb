{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.5\n",
      "2.0.9\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(json.__version__)\n",
    "#print(SentenceTransformer.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Files/titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('Files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "with open('Files/authors.pkl', 'rb') as f:\n",
    "    authors = pickle.load(f)\n",
    "\n",
    "with open('Files/years.pkl', 'rb') as f:\n",
    "    years = pickle.load(f)\n",
    "\n",
    "with open('Files/summary.pkl', 'rb') as f:\n",
    "    summary = pickle.load(f)\n",
    "\n",
    "index = pickle.load(open('Files/index.sav' , 'rb'))\n",
    "\n",
    "#model = pickle.load(open('Files/model.sav' , 'rb'))\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple query to return the first 5 similar documents (Titles, Authors, Years, Summary)\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = []\n",
    "    for i in range(k):\n",
    "        results.append(\n",
    "            { \n",
    "                'Title': titles[I[0][i]],\n",
    "                'Author': authors[I[0][i]],\n",
    "                'Year': years[I[0][i]],\n",
    "                'Summary': summary[I[0][i]]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Title': 'Minecraft: An Engaging Platform to Learn Programming', 'Author': 'Worasait Suwannik', 'Year': 2022, 'Summary': 'Teaching programming effectively is difficult. This paper explores the\\nbenefits of using Minecraft Education Edition to teach Python programming.\\nEducators can use the game to teach various programming concepts ranging from\\nfundamental programming concepts, object-oriented programming, event-driven\\nprogramming, and parallel programming. It has several benefits, including being\\nhighly engaging, sharpen creativity and problem-solving skill, motivating the\\nstudy of mathematics, and making students realizes the importance of\\nprogramming.'}, {'Title': 'Improving Learning from Demonstrations by Learning from Experience', 'Author': 'Marcelo H Ang Jr', 'Year': 2021, 'Summary': 'How to make imitation learning more general when demonstrations are\\nrelatively limited has been a persistent problem in reinforcement learning\\n(RL). Poor demonstrations lead to narrow and biased date distribution,\\nnon-Markovian human expert demonstration makes it difficult for the agent to\\nlearn, and over-reliance on sub-optimal trajectories can make it hard for the\\nagent to improve its performance. To solve these problems we propose a new\\nalgorithm named TD3fG that can smoothly transition from learning from experts\\nto learning from experience. Our algorithm achieves good performance in the\\nMUJOCO environment with limited and sub-optimal demonstrations. We use behavior\\ncloning to train the network as a reference action generator and utilize it in\\nterms of both loss function and exploration noise. This innovation can help\\nagents extract a priori knowledge from demonstrations while reducing the\\ndetrimental effects of the poor Markovian properties of the demonstrations. It\\nhas a better performance compared to the BC+ fine-tuning and DDPGfD approach,\\nespecially when the demonstrations are relatively limited. We call our method\\nTD3fG meaning TD3 from a generator.'}, {'Title': 'Pen and Paper Exercises in Machine Learning', 'Author': 'Michael U. Gutmann', 'Year': 2022, 'Summary': 'This is a collection of (mostly) pen-and-paper exercises in machine learning.\\nThe exercises are on the following topics: linear algebra, optimisation,\\ndirected graphical models, undirected graphical models, expressive power of\\ngraphical models, factor graphs and message passing, inference for hidden\\nMarkov models, model-based learning (including ICA and unnormalised models),\\nsampling and Monte-Carlo integration, and variational inference.'}, {'Title': 'The Physics of Learning', 'Author': 'Sahar Basiri-Esfahani', 'Year': 2022, 'Summary': 'A learning machine, like all machines, is an open system driven far from\\nthermal equilibrium by access to a low entropy source of free energy. We\\ndiscuss the connection between machines that learn, with low probability of\\nerror, and the optimal use of thermodynamic resources for both classical and\\nquantum machines. Both fixed point and spiking perceptrons are discussed in the\\ncontext of possible physical implementations. An example of a single photon\\nquantum kernel evaluation illustrates the important role for quantum coherence\\nin data representation. Machine learning algorithms, implemented on\\nconventional complementary metal oxide semiconductor (CMOS) devices, currently\\nconsume large amounts of energy. By focusing on the physical constraints of\\nlearning machines rather than algorithms, we suggest that a more efficient\\nmeans of implementing learning may be possible based on quantum switches\\noperating at very low power. Single photon kernel evaluation is an example of\\nthe energy efficiency that might be possible.'}, {'Title': 'Discover Life Skills for Planning with Bandits via Observing and\\n  Learning How the World Works', 'Author': 'Tin Lai', 'Year': 2022, 'Summary': \"We propose a novel approach for planning agents to compose abstract skills\\nvia observing and learning from historical interactions with the world. Our\\nframework operates in a Markov state-space model via a set of actions under\\nunknown pre-conditions. We formulate skills as high-level abstract policies\\nthat propose action plans based on the current state. Each policy learns new\\nplans by observing the states' transitions while the agent interacts with the\\nworld. Such an approach automatically learns new plans to achieve specific\\nintended effects, but the success of such plans is often dependent on the\\nstates in which they are applicable. Therefore, we formulate the evaluation of\\nsuch plans as infinitely many multi-armed bandit problems, where we balance the\\nallocation of resources on evaluating the success probability of existing arms\\nand exploring new options. The result is a planner capable of automatically\\nlearning robust high-level skills under a noisy environment; such skills\\nimplicitly learn the action pre-condition without explicit knowledge. We show\\nthat this planning approach is experimentally very competitive in\\nhigh-dimensional state space domains.\"}]\n"
     ]
    }
   ],
   "source": [
    "# testing ðŸ˜€\n",
    "query = 'What is the best way to learn Python?'\n",
    "results = retrieve(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data):\n",
    "    base_path = 'Sample_jsons/'\n",
    "    excportpath = base_path + 'excport.json'\n",
    "    with open(excportpath, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    \n",
    "    print('JSON file created successfully')\n",
    "    return excportpath\n",
    "\n",
    "# testing ðŸ˜€\n",
    "write_json(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list of dictionaries to json file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Gardio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=retrieve,\n",
    "    inputs = gr.inputs.Textbox(lines=1, placeholder=\"Enter Query...\", label=\"Query text\"),\n",
    "    # a json output with 4 keys: titles, authors, years, summary\n",
    "    outputs = gr.outputs.JSON(label=\"Similar Documents\"),\n",
    "    title=\"Semantic Search\",\n",
    "    description=\"Search for similar documents using semantic search.\",\n",
    "    allow_flagging=False,\n",
    "    examples=[\n",
    "        [\"Mathematical models of the spread of infectious diseases in humans and animals\"],\n",
    "        [\"A new method for solving the nonlinear eigenvalue problem\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7febc6ad48e0>, 'http://127.0.0.1:7862/', None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.launch(inline=True, inbrowser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reserves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = {'titles': [], 'authors': [], 'years': [], 'summary': []}\n",
    "    for i in range(k):\n",
    "        results['titles'].append(titles[I[0][i]])\n",
    "        results['authors'].append(authors[I[0][i]])\n",
    "        results['years'].append(years[I[0][i]])\n",
    "        results['summary'].append(summary[I[0][i]])\n",
    "    \n",
    "    return results\n",
    "    #return [titles[i] for i in I[0]], [authors[i] for i in I[0]], [years[i] for i in I[0]], [summary[i] for i in I[0]]\n",
    "\n",
    "\n",
    "for i in range(len(results['titles'])):\n",
    "    print(results['titles'][i])\n",
    "    print(results['authors'][i])\n",
    "    print(results['years'][i])\n",
    "    print(results['summary'][i])\n",
    "    print('----------------------------------------' * 2)\n",
    "\n",
    "\n",
    "# write each item in the list to a json file on new line\n",
    "with open('results2.json', 'w') as f:\n",
    "    for item in results:\n",
    "        json.dump(item, f)\n",
    "        f.write('\\n' % item)\n",
    "\n",
    "\n",
    "# simple query to return the first 5 similar documents (Titles, Authors, Years, Summary)\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "\n",
    "    results = {'Result 1': [], 'Result 2': [], 'Result 3': [], 'Result 4': [], 'Result 5': []}\n",
    "    for i in range(k):\n",
    "        results['Result '+str(i+1)].append(titles[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(authors[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(years[I[0][i]])\n",
    "        results['Result '+str(i+1)].append(summary[I[0][i]])\n",
    "    return results\n",
    "\n",
    "\n",
    "## Draft for json output\n",
    "k = 5 # number of similar documents to return\n",
    "xq = model.encode(['Africa Technology'])\n",
    "D, I = index.search(xq, k)\n",
    "\n",
    "# store all dictionaries in a list\n",
    "results = []\n",
    "\n",
    "for i in range(k):\n",
    "    results.append({\n",
    "        'Title': titles[I[0][i]],\n",
    "        'Author': authors[I[0][i]],\n",
    "        'Year': years[I[0][i]],\n",
    "        'Summary': summary[I[0][i]]\n",
    "    })\n",
    "\n",
    "# write list of dictionaries to json file\n",
    "with open('results3.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 06:36:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
