{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "titles_path = 'Files/titles.pkl'\n",
    "embeddings_path = 'Files/embeddings.pkl'\n",
    "authors_path = 'Files/authors.pkl'\n",
    "years_path = 'Files/years.pkl'\n",
    "summary_path = 'Files/summary.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy array from pickle file\n",
    "with open('Files/titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('Files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "with open('Files/authors.pkl', 'rb') as f:\n",
    "    authors = pickle.load(f)\n",
    "\n",
    "with open('Files/years.pkl', 'rb') as f:\n",
    "    years = pickle.load(f)\n",
    "\n",
    "with open('Files/summary.pkl', 'rb') as f:\n",
    "    summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "titles = np.array(titles)\n",
    "embeddings = np.array(embeddings)\n",
    "authors = np.array(authors)\n",
    "years = np.array(years)\n",
    "summary = np.array(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk as a pickle file\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "384\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "sample = 'What is the best way to learn Python?'\n",
    "#print(model.encode([sample]))\n",
    "#print(loaded_model.encode([sample]))\n",
    "print('---------------------' * 3)\n",
    "print(len(model.encode([sample])[0]))\n",
    "print(len(loaded_model.encode([sample])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "nlist = 50\n",
    "m = 8\n",
    "bits = 8\n",
    "dimensions = embeddings.shape[1]\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(dimensions)\n",
    "index = faiss.IndexIVFPQ(quantizer, dimensions, nlist, m, bits)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "index.train(embeddings)\n",
    "index.add(embeddings)\n",
    "print(index.ntotal)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index to disk as a pickle file\n",
    "index_filename = 'index.sav'\n",
    "pickle.dump(index, open(index_filename, 'wb'))\n",
    "\n",
    "# load the index from disk\n",
    "loaded_index = pickle.load(open(index_filename , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.174143  1.2508657 1.2596219 1.2784854 1.2793882]]\n",
      "CPU times: user 109 ms, sys: 29.1 ms, total: 138 ms\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 5\n",
    "D, I = index.search(model.encode([str(input(\"Enter Query: \"))]), k)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15695  7873 15016 18628 10918]]\n"
     ]
    }
   ],
   "source": [
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15695: FNTF: First No-reference Then Full-reference image quality assessment using Dark Channel.',\n",
       " '7873: Rectification of figures and photos in document images using bounding box interface.',\n",
       " '15016: Design and Implementation of QoS-driven Dynamic Slot Assignment and Piconet Partitioning Algorithms over Bluetooth WPANs.',\n",
       " '18628: PiCode: 2D barcode with embedded picture and ViCode: 3D barcode with embedded video.',\n",
       " '10918: MANTRA: Minimum Maximum Latent Structural SVM for Image Classification and Ranking.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {titles[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Learning Where You Are Going and from Whence You Came: h- and g-Cost Learning in Real-Time Heuristic Search.',\n",
       " 'Learning by Reading: A Prototype System, Performance Baseline and Lessons Learned.',\n",
       " 'Integrating learning objects into an open learning environment: evaluation of learning processes in an informatics learning lab.',\n",
       " 'Typing Tutor: Individualized Tutoring in Text Entry for Older Adults Based on Input Stumble Detection.',\n",
       " 'Analogy Tutor: A Tutoring System for Promoting Conceptual Learning via Comparison.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample function to get the top k similar documents, with default k=5\n",
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    D, I = index.search(model.encode([query]), k)\n",
    "    return [titles[i] for i in I[0]]\n",
    "\n",
    "get_similar_documents('What is the best way to learn Python?', loaded_index, loaded_model, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    D, I = index.search(model.encode([query]), k)\n",
    "    for i in I:\n",
    "        print(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bits of History, Challenges for the Future and Autonomic Computing Technology.'\n",
      " 'Empirically Studying Software Practitioners - Bridging the Gap between Theory and Practice.'\n",
      " 'The evolution of C programming practices: a study of the Unix operating system 1973-2015.'\n",
      " 'A living laboratory for the design and evaluation of ubiquitous computing technologies.'\n",
      " '15 Years of Application of Statistical Physics Methods to the Study of Software Systems.']\n"
     ]
    }
   ],
   "source": [
    "query = str(input(\"Enter Query: \"))\n",
    "get_similar_documents(query, loaded_index, loaded_model, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brief Announcement: Fast and Simple Node Coloring in the SINR Model.'\n",
      " 'The Dirac-Motzkin Problem on Ordinary Lines and the Orchard Problem (Invited Talk).'\n",
      " 'Compressed suffix arrays and suffix trees with applications to text indexing and string matching (extended abstract).'\n",
      " 'Linear-Time Algorithms for Two Subtree-Comparison Problems on Phylogenetic Trees with Different Species.'\n",
      " 'Minimal Tail-Biting Trellises for Certain Cyclic Block Codes Are Easy to Construct.']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# load numpy arrays from pickle file\n",
    "\"\"\" with open('titles_np.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f) \"\"\"\n",
    "\n",
    "'''with open('embeddings_np.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)'''\n",
    "\n",
    "# load the model\n",
    "#model = pickle.load(open('model.sav' , 'rb'))\n",
    "\n",
    "# load the index from disk\n",
    "#index = pickle.load(open('index.sav' , 'rb'))\n",
    "\n",
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq\n",
    "\n",
    "\n",
    "def get_similar_documents(query, index, model, titles, k=5):\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "    for i in I:\n",
    "        print(titles[i])\n",
    "\n",
    "query = str(input(\"Enter Query: \"))\n",
    "get_similar_documents(query, index, model, titles)\n",
    "\n",
    "#get_similar_documents('What is the best way to learn Python?', index, model, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Galaxies in the Shadows of Quasars with Gaussian Processes.\n"
     ]
    }
   ],
   "source": [
    "with open('titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "# convert to numpy array\n",
    "titles = np.array(titles)\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# ----------------- model  -----------------\n",
    "#model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "# load model\n",
    "model = pickle.load(open('model.sav' , 'rb'))\n",
    "\n",
    "# ----------------- faiss_index  -----------------\n",
    "nlist = 50\n",
    "m = 8\n",
    "bits = 8\n",
    "dimensions = embeddings.shape[1]\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(dimensions)\n",
    "index = faiss.IndexIVFPQ(quantizer, dimensions, nlist, m, bits)\n",
    "index.train(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "# ----------------- search  -----------------\n",
    "\n",
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq\n",
    "\n",
    "def get_similar_documents(query, index=index, model=model, titles=titles, k=5):\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "   \n",
    "    print(titles[I[0][0]])\n",
    "\n",
    "\n",
    "query = 'Quavo'\n",
    "get_similar_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(query):\n",
    "    xq = model.encode([query])\n",
    "    return xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(query):\n",
    "    k = 10\n",
    "    xq = get_embeddings(str(query))\n",
    "    D, I = index.search(xq, k)\n",
    "    # return list of similar documents\n",
    "    return [titles[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test funct.\n",
    "def name(text):\n",
    "    return 'Hello ' + text, 'Hello ' + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello John', 'Hello John')\n",
      "['Floats and Ropes: A Case Study for Formal Numerical Program Verification.', 'Digital Libraries: Extending and Applying Library and Information Science and Technology.', 'The fractal dimension metric and its use to assess object-oriented software quality.', 'UX research: what theoretical roots do we build on - if any?', \"Don't look now, but we've created a bureaucracy: the nature and roles of policies and rules in wikipedia.\", 'Academic Software Engineering: What Is and What Could Be? Results of the First Annual Survey for International SE Programs.', \"Design requirements for more flexible structured editors from a study of programmers' text editing.\", 'Ten steps of integrating user feedback into the product definition process: a closed loop approach.', 'Using knowledge elicitation to improve Web effort estimation: Lessons from six industrial case studies.', 'Java Program Analysis Projects in Osaka University: Aspect-Based Slicing System ADAS and Ranked-Component Search System SPARS-J.']\n"
     ]
    }
   ],
   "source": [
    "print(name('John'))\n",
    "print(get_similar_documents('maths'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=get_similar_documents,\n",
    "    inputs = gr.Textbox(lines=1, placeholder=\"Enter Query...\", label=\"Query\"),\n",
    "\n",
    "    # variable number of outputs based on the number of results argument \n",
    "    outputs = [ gr.outputs.Textbox(label=\"First similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Second similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Third similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Fourth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Fifth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Sixth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Seventh similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Eighth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Ninth similar document\"),\n",
    "                gr.outputs.Textbox(label=\"Tenth similar document\")],\n",
    "   \n",
    "    title=\"Search Engine\",\n",
    "    description=\"Search Engine using Sentence Transformers and Faiss Indexing\",\n",
    "    allow_flagging=False,\n",
    "    allow_screenshot=False,\n",
    "    allow_output_caching=False,\n",
    "\n",
    "    )\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2, (desiging retrerival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Files/titles.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)\n",
    "\n",
    "with open('Files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "with open('Files/authors.pkl', 'rb') as f:\n",
    "    authors = pickle.load(f)\n",
    "\n",
    "with open('Files/years.pkl', 'rb') as f:\n",
    "    years = pickle.load(f)\n",
    "\n",
    "with open('Files/summary.pkl', 'rb') as f:\n",
    "    summary = pickle.load(f)\n",
    "\n",
    "index = pickle.load(open('Files/index.sav' , 'rb'))\n",
    "\n",
    "#model = pickle.load(open('Files/model.sav' , 'rb'))\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(index.ntotal)\n",
    "print(index.is_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple query to return the first 5 similar documents (Titles, Authors, Years, Summary)\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    xq = model.encode([query])\n",
    "    D, I = index.search(xq, k)\n",
    "    return [titles[i] for i in I[0]], [authors[i] for i in I[0]], [years[i] for i in I[0]], [summary[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent Advances of Blockchain and its Applications  by:  Weili Wu 2022\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Blockchain is an emerging decentralized data collection, sharing and storage\n",
      "technology, which have provided abundant transparent, secure, tamper-proof,\n",
      "secure and robust ledger services for various real-world use cases. Recent\n",
      "years have witnessed notable developments of blockchain technology itself as\n",
      "well as blockchain-adopting applications. Most existing surveys limit the\n",
      "scopes on several particular issues of blockchain or applications, which are\n",
      "hard to depict the general picture of current giant blockchain ecosystem. In\n",
      "this paper, we investigate recent advances of both blockchain technology and\n",
      "its most active research topics in real-world applications. We first review the\n",
      "recent developments of consensus mechanisms and storage mechanisms in general\n",
      "blockchain systems. Then extensive literature is conducted on blockchain\n",
      "enabled IoT, edge computing, federated learning and several emerging\n",
      "applications including healthcare, COVID-19 pandemic, social network and supply\n",
      "chain, where detailed specific research topics are discussed in each. Finally,\n",
      "we discuss the future directions, challenges and opportunities in both academia\n",
      "and industry.\n",
      "\n",
      "====================================================================================================\n",
      "Application of Blockchain Technology for Educational Platform  by:  N. Draskovic 2021\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Nowadays, huge amounts of data are generated every second, and a quantity of\n",
      "that data can be defined as sensitive. Blockchain technology has private,\n",
      "secure, transparent and decentralized exchange of data as native. It is\n",
      "adaptable and can be used in a wide range of Internet-based interactive systems\n",
      "in academic and industrial settings. The essential part of programmable\n",
      "distributed ledgers such as Ethereum, Polkadot, Cardano and other Web 3.0\n",
      "technologies are smart contracts. Smart contracts are programs executed on the\n",
      "global blockchain, the code is public as well as all of the data managed within\n",
      "the transactions, thus creating a system that is reliable and cannot be cheated\n",
      "if designed properly. In this paper, in order to make the educational system\n",
      "more transparent and versatile we will describe an educational learning\n",
      "platform designed as a distributed system.\n",
      "\n",
      "====================================================================================================\n",
      "Blockchain and Beyond: Understanding Blockchains through Prototypes and\n",
      "  Public Engagement  by:  Chris Speed 2021\n",
      "----------------------------------------------------------------------------------------------------\n",
      "This paper presents an annotated portfolio of projects that seek to\n",
      "understand and communicate the social and societal implications of blockchains,\n",
      "distributed ledgers and smart contracts. These complex technologies rely on\n",
      "human and technical factors to deliver cryptocurrencies, shared computation and\n",
      "trustless protocols but have a secondary benefit in providing a moment to\n",
      "re-think many aspects of society, and imagine alternative possibilities. The\n",
      "projects use design and HCI methods to relate blockchains to a range of topics,\n",
      "including global supply chains, delivery infrastructure, smart grids,\n",
      "volunteering and charitable giving, through engaging publics, exploring ideas\n",
      "and speculating on possible futures. Based on an extensive annotated portfolio\n",
      "we draw out learning for the design of blockchain systems, broadening\n",
      "participation and surfacing questions around imaginaries, social implications\n",
      "and engagement with new technology. This paints a comprehensive picture of how\n",
      "HCI and design can shape understandings of the future of complex technologies.\n",
      "\n",
      "====================================================================================================\n",
      "A Blockchain-Based Approach for Collaborative Formalization of\n",
      "  Mathematics and Programs  by:  Georgios Piliouras 2021\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Formalization of mathematics is the process of digitizing mathematical\n",
      "knowledge, which allows for formal proof verification as well as efficient\n",
      "semantic searches. Given the large and ever-increasing gap between the set of\n",
      "formalized and unformalized mathematical knowledge, there is a clear need to\n",
      "encourage more computer scientists and mathematicians to solve and formalize\n",
      "mathematical problems together. With blockchain technology, we are able to\n",
      "decentralize this process, provide time-stamped verification of authorship and\n",
      "encourage collaboration through implementation of incentive mechanisms via\n",
      "smart contracts. Currently, the formalization of mathematics is done through\n",
      "the use of proof assistants, which can be used to verify programs and protocols\n",
      "as well. Furthermore, with the advancement in artificial intelligence (AI),\n",
      "particularly machine learning, we can apply automated AI reasoning tools in\n",
      "these proof assistants and (at least partially) automate the process of\n",
      "synthesizing proofs. In our paper, we demonstrate a blockchain-based system for\n",
      "collaborative formalization of mathematics and programs incorporating both\n",
      "human labour as well as automated AI tools. We explain how Token-Curated\n",
      "Registries (TCR) and smart contracts are used to ensure appropriate documents\n",
      "are recorded and encourage collaboration through implementation of incentive\n",
      "mechanisms respectively. Using an illustrative example, we show how formalized\n",
      "proofs of different sorting algorithms can be produced collaboratively in our\n",
      "proposed blockchain system.\n",
      "\n",
      "====================================================================================================\n",
      "A Systematic Literature Review on Blockchain Enabled Federated Learning\n",
      "  Framework for Internet of Vehicles  by:  Rafiqul Islam 2022\n",
      "----------------------------------------------------------------------------------------------------\n",
      "While the convergence of Artificial Intelligence (AI) techniques with\n",
      "improved information technology systems ensured enormous benefits to the\n",
      "Internet of Vehicles (IoVs) systems, it also introduced an increased amount of\n",
      "security and privacy threats. To ensure the security of IoVs data, privacy\n",
      "preservation methodologies have gained significant attention in the literature.\n",
      "However, these strategies also need specific adjustments and modifications to\n",
      "cope with the advances in IoVs design. In the interim, Federated Learning (FL)\n",
      "has been proven as an emerging idea to protect IoVs data privacy and security.\n",
      "On the other hand, Blockchain technology is showing prominent possibilities\n",
      "with secured, dispersed, and auditable data recording and sharing schemes. In\n",
      "this paper, we present a comprehensive survey on the application and\n",
      "implementation of Blockchain-Enabled Federated Learning frameworks for IoVs.\n",
      "Besides, probable issues, challenges, solutions, and future research directions\n",
      "for BC-Enabled FL frameworks for IoVs are also presented. This survey can\n",
      "further be used as the basis for developing modern BC-Enabled FL solutions to\n",
      "resolve different data privacy issues and scenarios of IoVs.\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#results = retrieve('maths')\n",
    "results = retrieve(str(input(\"Enter Query: \")))\n",
    "\n",
    "# print Title, Author, Year, Summary of the first 5 similar documents\n",
    "for i in range(len(results[0])):\n",
    "    print(results[0][i],\" by: \" , results[1][i], results[2][i])\n",
    "    print(\"-------------------------\" * 4)\n",
    "    print(results[3][i])\n",
    "    print()\n",
    "    print(\"=========================\" * 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4524e0aa81b3ae16e25dcf9b33e91112c133dfc9ef43cc517d5da5b8fe0f3eee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
